#!/usr/bin/env python
# coding: utf-8

# <h1 align=center><font size = 5>Toronto Clustering Assignment by Ryan Diaz-Perez</font></h1>

# <h1 align=left><font size = 4>Part 1: Web Scraping</font></h1>

# In[14]:


import numpy as np # library to handle data in a vectorized manner
import pandas as pd # library for data analsysis
from sklearn.cluster import KMeans # import k-means from clustering stage


# <Big><b>Extracting data from the Wikipedia page</b></Big>

# In[15]:


df_toronto = pd.read_html("https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M", flavor="html5lib")[0]

# Removing rows with Borough value of Not assigned
df_toronto.drop(df_toronto.index[df_toronto['Borough'] == 'Not assigned'], inplace = True)
df_toronto.head()


# In[16]:


# Combining rows
df_toronto = df_toronto.groupby(by=['Postcode','Borough']).agg(lambda x: ','.join(x))
df_toronto.reset_index(level=['Postcode','Borough'], inplace=True)
df_toronto.head(210)


# In[17]:


df_toronto.loc[df_toronto['Neighbourhood'] == ('Not assigned'), 'Neighbourhood'] = df_toronto['Borough']
df_toronto.head(90)


# In[18]:


df_toronto.shape


# <h1 align=left><font size = 4>Part 2: Geographical locations</font></h1>

# In[ ]:





# In[ ]:





# In[ ]:





# <h1 align=left><font size = 4>Part 3: Maps of the neighborhood</font></h1>

# In[ ]:





# In[ ]:





# In[ ]:




